{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "file_path = r\"D:\\Inzpire-Solutions\\Training\\merged_data_original_transformed.csv\"\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(data.info())\n",
    "    print(data.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "\n",
    "categorical_columns = ['Crate']\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "try:\n",
    "    encoded_columns = encoder.fit_transform(data[categorical_columns])\n",
    "    encoded_column_names = encoder.get_feature_names_out(categorical_columns)\n",
    "    encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names, index=data.index)\n",
    "    data = pd.concat([data.drop(categorical_columns, axis=1), encoded_df], axis=1)\n",
    "except Exception as e:\n",
    "    print(f\"Error in one-hot encoding: {e}\")\n",
    "\n",
    "\n",
    "X = data.drop(['GrossWeight',\"_id\"], axis=1)\n",
    "y = data[\"GrossWeight\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = SVR(kernel='linear', C=8, epsilon=0.09)\n",
    "\n",
    "try:\n",
    "    model.fit(X_train, y_train)\n",
    "except Exception as e:\n",
    "    print(f\"Error in training model: {e}\")\n",
    "\n",
    "try:\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in prediction or evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "file_path = \"/content/merged_data_original_transformed.csv\"\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(data.info())\n",
    "    print(data.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "\n",
    "categorical_columns = ['Crate']\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "try:\n",
    "    encoded_columns = encoder.fit_transform(data[categorical_columns])\n",
    "    encoded_column_names = encoder.get_feature_names_out(categorical_columns)\n",
    "    encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names, index=data.index)\n",
    "    data = pd.concat([data.drop(categorical_columns, axis=1), encoded_df], axis=1)\n",
    "except Exception as e:\n",
    "    print(f\"Error in one-hot encoding: {e}\")\n",
    "\n",
    "X = data.drop(['GrossWeight', '_id'], axis=1)\n",
    "y = data['GrossWeight']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class TransformerRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_layers):\n",
    "        super(TransformerRegressor, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer(x.unsqueeze(1))\n",
    "        x = self.fc(x[:, 0, :])\n",
    "        return x\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "embed_dim = 64\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "model = TransformerRegressor(input_dim, embed_dim, num_heads, num_layers)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs.squeeze(), y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = model(X_test_tensor).squeeze()\n",
    "    y_pred = y_pred_tensor.numpy()\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 499/500, Loss: 5330.1343\n",
    "\n",
    "Epoch 500/500, Loss: 5329.8823\n",
    "\n",
    "Root Mean Squared Error (RMSE): 18.05666188994635\n",
    "\n",
    "Mean Absolute Error (MAE): 15.878791025855161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3297 entries, 0 to 3296\n",
      "Columns: 187 entries, _id to GM_40kg\n",
      "dtypes: float64(185), int64(1), object(1)\n",
      "memory usage: 4.7+ MB\n",
      "None\n",
      "                        _id  Crate  NetWeight  GrossWeight  KMR_1.5kg  \\\n",
      "0  66cdbe64547097decd66003e  20259      5.562     6.500000        1.0   \n",
      "1  66cdbeaa547097decd660042  10067      2.652     6.600000        0.0   \n",
      "2  66ed1639abaa2c70c8da8974  40021     28.602    36.599998        0.0   \n",
      "3  66ed163fabaa2c70c8da8977  20293     26.536    34.599998        0.0   \n",
      "4  66ed18d5abaa2c70c8da8a39  40098     29.986    37.950001        0.0   \n",
      "\n",
      "   MUT_2kg  PR_2kg  KAB_1kg  MS_0.5kg  NM_1kg  ...  BI_1.5kg  SID_1kg  \\\n",
      "0      1.0     1.0      0.0       0.0     0.0  ...       0.0      0.0   \n",
      "1      0.0     0.0      1.0       1.0     1.0  ...       0.0      0.0   \n",
      "2      0.0     0.0      3.0       4.0     5.0  ...       0.0      0.0   \n",
      "3      0.0     0.0      4.0       4.0     2.0  ...       0.0      0.0   \n",
      "4      0.0     0.0      2.0       4.0     3.0  ...       0.0      0.0   \n",
      "\n",
      "   GKB_1.5kg  STR_2.5kg  AYSL_1.5kg  AYSL_0.5kg  SVR1_1kg  GD1_1kg  PT_1.5kg  \\\n",
      "0        0.0        0.0         0.0         0.0       0.0      0.0       0.0   \n",
      "1        0.0        0.0         0.0         0.0       0.0      0.0       0.0   \n",
      "2        0.0        0.0         0.0         0.0       0.0      0.0       0.0   \n",
      "3        0.0        0.0         0.0         0.0       0.0      0.0       0.0   \n",
      "4        0.0        0.0         0.0         0.0       0.0      0.0       0.0   \n",
      "\n",
      "   GM_40kg  \n",
      "0      0.0  \n",
      "1      0.0  \n",
      "2      0.0  \n",
      "3      0.0  \n",
      "4      0.0  \n",
      "\n",
      "[5 rows x 187 columns]\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters for Random Forest: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "Random Forest - Root Mean Squared Error (RMSE): 6.910000283483251\n",
      "Random Forest - Mean Absolute Error (MAE): 5.115664131479822\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "file_path = r\"D:\\Inzpire-Solutions\\Training\\merged_data_original_transformed.csv\"\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(data.info())\n",
    "    print(data.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "\n",
    "data.columns = data.columns.astype(str)\n",
    "\n",
    "categorical_columns = ['Crate']\n",
    "encoder = OneHotEncoder(sparse_output=True, handle_unknown='ignore')\n",
    "try:\n",
    "    encoded_columns = encoder.fit_transform(data[categorical_columns])\n",
    "    encoded_column_names = encoder.get_feature_names_out(categorical_columns)\n",
    "    encoded_df = pd.DataFrame.sparse.from_spmatrix(encoded_columns, index=data.index, columns=encoded_column_names)\n",
    "    data = pd.concat([data.drop(categorical_columns, axis=1), encoded_df], axis=1)\n",
    "except Exception as e:\n",
    "    print(f\"Error in one-hot encoding: {e}\")\n",
    "\n",
    "X = data.drop(['GrossWeight', '_id'], axis=1)\n",
    "y = data['GrossWeight']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "try:\n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_rf = random_search.best_estimator_\n",
    "    print(\"Best Parameters for Random Forest:\", random_search.best_params_)\n",
    "except Exception as e:\n",
    "    print(f\"Error in Random Forest hyperparameter tuning: {e}\")\n",
    "\n",
    "try:\n",
    "    y_pred_rf = best_rf.predict(X_test)\n",
    "    rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "    mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "    print(f\"Random Forest - Root Mean Squared Error (RMSE): {rmse_rf}\")\n",
    "    print(f\"Random Forest - Mean Absolute Error (MAE): {mae_rf}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in model evaluation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3297 entries, 0 to 3296\n",
      "Columns: 187 entries, _id to GM_40kg\n",
      "dtypes: float64(185), int64(1), object(1)\n",
      "memory usage: 4.7+ MB\n",
      "None\n",
      "                        _id  Crate  NetWeight  GrossWeight  KMR_1.5kg  \\\n",
      "0  66cdbe64547097decd66003e  20259      5.562     6.500000        1.0   \n",
      "1  66cdbeaa547097decd660042  10067      2.652     6.600000        0.0   \n",
      "2  66ed1639abaa2c70c8da8974  40021     28.602    36.599998        0.0   \n",
      "3  66ed163fabaa2c70c8da8977  20293     26.536    34.599998        0.0   \n",
      "4  66ed18d5abaa2c70c8da8a39  40098     29.986    37.950001        0.0   \n",
      "\n",
      "   MUT_2kg  PR_2kg  KAB_1kg  MS_0.5kg  NM_1kg  ...  BI_1.5kg  SID_1kg  \\\n",
      "0      1.0     1.0      0.0       0.0     0.0  ...       0.0      0.0   \n",
      "1      0.0     0.0      1.0       1.0     1.0  ...       0.0      0.0   \n",
      "2      0.0     0.0      3.0       4.0     5.0  ...       0.0      0.0   \n",
      "3      0.0     0.0      4.0       4.0     2.0  ...       0.0      0.0   \n",
      "4      0.0     0.0      2.0       4.0     3.0  ...       0.0      0.0   \n",
      "\n",
      "   GKB_1.5kg  STR_2.5kg  AYSL_1.5kg  AYSL_0.5kg  SVR1_1kg  GD1_1kg  PT_1.5kg  \\\n",
      "0        0.0        0.0         0.0         0.0       0.0      0.0       0.0   \n",
      "1        0.0        0.0         0.0         0.0       0.0      0.0       0.0   \n",
      "2        0.0        0.0         0.0         0.0       0.0      0.0       0.0   \n",
      "3        0.0        0.0         0.0         0.0       0.0      0.0       0.0   \n",
      "4        0.0        0.0         0.0         0.0       0.0      0.0       0.0   \n",
      "\n",
      "   GM_40kg  \n",
      "0      0.0  \n",
      "1      0.0  \n",
      "2      0.0  \n",
      "3      0.0  \n",
      "4      0.0  \n",
      "\n",
      "[5 rows x 187 columns]\n",
      "Stacked Model - RMSE: 8.60375685417756\n",
      "Stacked Model - MAE: 6.538407095184639\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters for Random Forest: {'n_estimators': 100, 'min_samples_split': 20, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None}\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters for XGBoost: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.6}\n",
      "Random Forest - RMSE: 6.653985689281253\n",
      "Random Forest - MAE: 5.076201866969966\n",
      "XGBoost - RMSE: 8.051818274559785\n",
      "XGBoost - MAE: 4.748692265989774\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "file_path = r\"D:\\Inzpire-Solutions\\Training\\merged_data_original_transformed.csv\"\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(data.info())\n",
    "    print(data.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "\n",
    "data.columns = data.columns.astype(str)\n",
    "\n",
    "categorical_columns = ['Crate']\n",
    "encoder = OneHotEncoder(sparse_output=True, handle_unknown='ignore')\n",
    "try:\n",
    "    encoded_columns = encoder.fit_transform(data[categorical_columns])\n",
    "    encoded_column_names = encoder.get_feature_names_out(categorical_columns)\n",
    "    encoded_df = pd.DataFrame.sparse.from_spmatrix(encoded_columns, index=data.index, columns=encoded_column_names)\n",
    "    data = pd.concat([data.drop(categorical_columns, axis=1), encoded_df], axis=1)\n",
    "except Exception as e:\n",
    "    print(f\"Error in one-hot encoding: {e}\")\n",
    "\n",
    "X = data.drop(['GrossWeight', '_id'], axis=1)\n",
    "y = data['GrossWeight']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=200, max_depth=30, min_samples_split=10, min_samples_leaf=2, random_state=42)\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=300, max_depth=10, learning_rate=0.1, random_state=42)\n",
    "\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=[('rf', rf_model), ('xgb', xgb_model)],\n",
    "    final_estimator=Ridge()\n",
    ")\n",
    "\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_stacked = stacking_model.predict(X_test)\n",
    "rmse_stacked = np.sqrt(mean_squared_error(y_test, y_pred_stacked))\n",
    "mae_stacked = mean_absolute_error(y_test, y_pred_stacked)\n",
    "print(f\"Stacked Model - RMSE: {rmse_stacked}\")\n",
    "print(f\"Stacked Model - MAE: {mae_stacked}\")\n",
    "\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [100, 200, 300, 500, 1000],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "param_dist_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 6, 10, 15],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    rf_model,\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "best_rf = random_search_rf.best_estimator_\n",
    "print(\"Best Parameters for Random Forest:\", random_search_rf.best_params_)\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    xgb_model,\n",
    "    param_distributions=param_dist_xgb,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "random_search_xgb.fit(X_train, y_train)\n",
    "best_xgb = random_search_xgb.best_estimator_\n",
    "print(\"Best Parameters for XGBoost:\", random_search_xgb.best_params_)\n",
    "\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest - RMSE: {rmse_rf}\")\n",
    "print(f\"Random Forest - MAE: {mae_rf}\")\n",
    "\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost - RMSE: {rmse_xgb}\")\n",
    "print(f\"XGBoost - MAE: {mae_xgb}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
